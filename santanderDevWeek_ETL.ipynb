{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKXAMLw+8oF3Yso4Cy12Ce",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimasrfaria/falvojr-santander-dev-week-2023/blob/master/santanderDevWeek_ETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FASE \"E\" -> EXTRACT**"
      ],
      "metadata": {
        "id": "JK71gMgnFwaH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7yyjlRtPFGon"
      },
      "outputs": [],
      "source": [
        "# --------------------------------\n",
        "# 1. Leitura do CSV de cadastro dos usuários com uso do pandas - Temos somente 3 usuários devido a limitação da API gratuita no Gemini que é a utilizada neste teste.\n",
        "# --------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('SDW2026.csv', sep=';')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FASE \"T\" -> TRANSFORMATION**"
      ],
      "metadata": {
        "id": "Z2gVI8JrGLfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Exibe informações sobre os dados para avaliação da Extração realizada (tipos e uso de memória)\n",
        "#df.info()\n",
        "\n",
        "#print(\"\\n\" * 3)  # 3 linha em branco para melhor visualização\n",
        "\n",
        "# --------------------------------\n",
        "# Exibe todas as informações em formato de tabela para avaliação dos dados\n",
        "# Usado desta forma, por saber que são poucos dados\n",
        "# --------------------------------\n",
        "\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" * 3)  # 3 linha em branco para melhor visualização\n",
        "\n",
        "# --------------------------------\n",
        "# 2. Importação das bibliotecas necessárias para implementação:\n",
        "# ✔ Timestamp para auditoria\n",
        "# ✔ Integração real com API OpenIA para mensagens personalizadas por usuário\n",
        "# ✔ Travalhar com \".env\" para evitar vazamento da chave OpenIA\n",
        "# --------------------------------\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# --------------------------------\n",
        "# 3. Escolha da IA (Somente utilizo o gemini para esse teste, pois a OpenIA não ofereceu a API gratuíta, mais verificado que esta funcionando.\n",
        "#    o erro que é gerado é somente devido a falta de crédito)\n",
        "# --------------------------------\n",
        "print(\"\\nSelecione a IA para geração das mensagens:\")\n",
        "print(\"1) OpenAI\")\n",
        "print(\"2) Gemini\")\n",
        "\n",
        "opcao = input(\"Digite 1 ou 2: \").strip()\n",
        "\n",
        "if opcao not in (\"1\", \"2\"):\n",
        "    raise ValueError(\"Opção inválida.\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 4. Carregar variáveis de ambiente e inicializa a API selecionada (OpenIA ou Gemini)\n",
        "# --------------------------------------------------\n",
        "load_dotenv()\n",
        "\n",
        "# --------------------------------\n",
        "# 5. Inicialização do provedor\n",
        "# --------------------------------\n",
        "provider = None\n",
        "\n",
        "if opcao == \"1\":\n",
        "    from openai import OpenAI\n",
        "\n",
        "    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not OPENAI_API_KEY:\n",
        "        raise RuntimeError(\"OPENAI_API_KEY não encontrada.\")\n",
        "\n",
        "    provider = \"openai\"\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "elif opcao == \"2\":\n",
        "    from google import genai\n",
        "    import time\n",
        "\n",
        "    GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
        "    if not GEMINI_API_KEY:\n",
        "        raise RuntimeError(\"GEMINI_API_KEY não encontrada.\")\n",
        "\n",
        "    provider = \"gemini\"\n",
        "    #genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "    #model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    client_gemini = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "\n",
        "# --------------------------------\n",
        "# 6. Função ÚNICA de geração\n",
        "# --------------------------------\n",
        "def gerar_news(usuario):\n",
        "    prompt = f\"\"\"\n",
        "    Você é um especialista em marketing bancário.\n",
        "\n",
        "    Crie uma mensagem curta, profissional e clara para o cliente abaixo,\n",
        "    incentivando o uso de soluções financeiras do banco.\n",
        "    Não use linguagem agressiva de vendas.\n",
        "\n",
        "    Nome do cliente: {usuario['Nome']}\n",
        "\n",
        "    Diretrizes:\n",
        "    - Tom institucional e profissional\n",
        "    - Linguagem clara e objetiva\n",
        "    - Não mencionar taxas, valores, nome do banco ou produtos específicos\n",
        "    - Não inventar informações pessoais\n",
        "    - Máximo de 3 frases\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        if provider == \"openai\":\n",
        "            resposta = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Você é um especialista em marketing bancário com foco em compliance.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.6,\n",
        "                max_tokens=120\n",
        "            )\n",
        "            return resposta.choices[0].message.content.strip()\n",
        "\n",
        "        elif provider == \"gemini\":\n",
        "            resposta = client_gemini.models.generate_content(\n",
        "                model=\"gemini-2.0-flash\",\n",
        "                contents=prompt\n",
        "            )\n",
        "            return resposta.text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro {provider} para o usuário {usuario['UserID']}: {e}\")\n",
        "        return (\n",
        "            \"Temos novidades financeiras pensadas para apoiar seus objetivos \"\n",
        "            \"com segurança e praticidade.\"\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Geração das mensagens (News)\n",
        "# -----------------------------\n",
        "news_geradas = []\n",
        "\n",
        "data_geracao = datetime.now().strftime(\"%d-%m-%y %H:%M:%S\")\n",
        "\n",
        "for _, usuario in df.iterrows():\n",
        "    news_geradas.append({\n",
        "        \"UserID\": usuario[\"UserID\"],\n",
        "        \"Nome\": usuario[\"Nome\"],\n",
        "        \"News\": gerar_news(usuario),\n",
        "        \"DataGeracao\": data_geracao\n",
        "\n",
        "    })\n",
        "\n",
        "    time.sleep(3)  # Pausa de 3 segundos entre cada cliente para não travar a API gratuita\n",
        "\n",
        "df_news = pd.DataFrame(news_geradas)\n",
        "print(\"\\n--- Fase transformation Finalizado ---\")\n"
      ],
      "metadata": {
        "id": "XsTWTiCPUpx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FASE \"L\" -> LOAD**"
      ],
      "metadata": {
        "id": "H6F9X-UTGdVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 8. Escrita no CSV com histórico\n",
        "# -----------------------------\n",
        "arquivo_saida = \"SDW2026_news.csv\"\n",
        "arquivo_existe = os.path.exists(arquivo_saida)\n",
        "\n",
        "df_news.to_csv(\n",
        "    arquivo_saida,\n",
        "    sep=\";\",\n",
        "    index=False,\n",
        "    encoding=\"utf-8\",\n",
        "    mode=\"a\",                 # append (mantém histórico)\n",
        "    header=not arquivo_existe # escreve cabeçalho só se o arquivo não existir\n",
        ")\n",
        "print(\"\\n--- Fase de Load Finalizado ---\")"
      ],
      "metadata": {
        "id": "UqKSd5PqVDDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e1a0b1a-f259-408e-d621-d5ea8c391ea5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fase de Load Finalizado ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Alguns dos comandos utilizados para instação e validação dos recursos utilizados**"
      ],
      "metadata": {
        "id": "r1lMLk5GH0ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------\n",
        "# Intalação da biblioteca, para suporte ao uso do .env no python, afim de ocultar a chave da OpenIA\n",
        "#-----------------------------\n",
        "\n",
        "#pip install python-dotenv"
      ],
      "metadata": {
        "id": "PDIOleVm-Uu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------\n",
        "#Teste de leitura para a variavel de ambiente \".env\"\n",
        "#-----------------------------\n",
        "\n",
        "#from dotenv import load_dotenv\n",
        "#load_dotenv()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O9elx91AIOg",
        "outputId": "425d8581-8b48-4e9a-99c1-3dcdd3b6ac62"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------\n",
        "# validar se está funcionando a chave de ambiente .env\n",
        "#-----------------------------\n",
        "\n",
        "#import os\n",
        "#print(os.getenv(\"GEMINI_API_KEY\"))"
      ],
      "metadata": {
        "id": "4pXE5qB-AQTc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}